{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b24db216",
   "metadata": {},
   "source": [
    "# Credit Card Fraud Detection - Data Exploration\n",
    "\n",
    "## HỌ VÀ TÊN: Cao Tấn Hoàng Huy\n",
    "## MSSV: 23127051"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d458b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Khai báo các thư viện cần thiết\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Setup\n",
    "np.random.seed(42)\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0701ba",
   "metadata": {},
   "source": [
    "# Data exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5292ae6c",
   "metadata": {},
   "source": [
    "## Load dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05b1f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/creditcard.csv', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "# Skip header và lấy tên columns\n",
    "header = lines[0].strip().replace('\"', '').split(',')\n",
    "print(f\"Found {len(header)} columns: {header}\")\n",
    "\n",
    "data_list = []\n",
    "error_lines = []\n",
    "\n",
    "for i, line in enumerate(lines[1:], 1):\n",
    "    try:\n",
    "        # Xử lý dòng và chuyển đổi sang float\n",
    "        line = line.strip()\n",
    "        if not line:  # Skip empty lines\n",
    "            continue\n",
    "            \n",
    "        values = line.split(',')\n",
    "        \n",
    "        # Remove quotes if present và convert to float\n",
    "        float_values = []\n",
    "        for val in values:\n",
    "            val = val.strip().strip('\"')\n",
    "            float_values.append(float(val))\n",
    "        \n",
    "        if len(float_values) == 31:  # Ensure we have all columns\n",
    "            data_list.append(float_values)\n",
    "        else:\n",
    "            error_lines.append((i, len(float_values)))\n",
    "            \n",
    "    except Exception as e:\n",
    "        error_lines.append((i, str(e)))\n",
    "        if len(error_lines) < 10:  # Only show first 10 errors\n",
    "            print(f\"Error at line {i}: {e}\")\n",
    "            print(f\"Line content: {line[:100]}\")\n",
    "\n",
    "if error_lines:\n",
    "    print(f\"Found {len(error_lines)} problematic lines\")\n",
    "else:\n",
    "    print(\"All lines parsed successfully\")\n",
    "\n",
    "data = np.array(data_list, dtype=np.float64)\n",
    "\n",
    "print(f\"\\nDATASET OVERVIEW:\")\n",
    "print(f\"Dataset loaded successfully!\")\n",
    "print(f\"Shape: {data.shape}\")\n",
    "print(f\"Type: {data.dtype}\")\n",
    "print(f\"Size: {data.nbytes / (1024*1024):.2f} MB\")\n",
    "\n",
    "# Tạo mapping cho columns\n",
    "column_names = header\n",
    "print(f\"\\nCOLUMN INFORMATION:\")\n",
    "for i, col_name in enumerate(column_names):\n",
    "    print(f\"Column {i:2d}: {col_name}\")\n",
    "\n",
    "# Quick preview của data\n",
    "print(f\"\\nDATA PREVIEW:\")\n",
    "print(f\"First 5 rows (showing Time, V1, V2, Amount, Class):\")\n",
    "preview_cols = [0, 1, 2, 29, 30]  # Time, V1, V2, Amount, Class\n",
    "preview_names = [column_names[i] for i in preview_cols]\n",
    "\n",
    "for i in range(min(5, data.shape[0])):\n",
    "    values = [f\"{data[i, col]:.2f}\" for col in preview_cols]\n",
    "    print(f\"   Row {i+1}: \" + \" | \".join(f\"{name}={val}\" for name, val in zip(preview_names, values)))\n",
    "\n",
    "# Basic statistics\n",
    "print(f\"\\nBASIC STATISTICS:\")\n",
    "print(f\"Total transactions: {data.shape[0]:,}\")\n",
    "print(f\"Total features: {data.shape[1]}\")\n",
    "\n",
    "# Class distribution\n",
    "class_column = data[:, -1]  # Last column is Class\n",
    "unique_classes, class_counts = np.unique(class_column, return_counts=True)\n",
    "print(f\"\\nCLASS DISTRIBUTION:\")\n",
    "for cls, count in zip(unique_classes, class_counts):\n",
    "    percentage = (count / len(class_column)) * 100\n",
    "    label = \"Normal\" if cls == 0.0 else \"Fraud\"\n",
    "    print(f\" {label} ({cls}): {count:>6,} transactions ({percentage:>5.2f}%)\")\n",
    "\n",
    "# Calculate imbalance ratio\n",
    "if len(unique_classes) == 2:\n",
    "    normal_count = class_counts[0] if unique_classes[0] == 0 else class_counts[1]\n",
    "    fraud_count = class_counts[1] if unique_classes[1] == 1 else class_counts[0]\n",
    "    imbalance_ratio = normal_count / fraud_count\n",
    "    print(f\"Imbalance ratio: {imbalance_ratio:.1f}:1 (Normal:Fraud)\")\n",
    "\n",
    "print(f\"\\nDataset ready for exploration!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539b1739",
   "metadata": {},
   "source": [
    "### Tổng kết Load dữ liệu\n",
    "\n",
    "**Kết quả:**\n",
    "- Dataset load thành công với **284,807 transactions** và **31 features**\n",
    "- Dung lượng: ~65 MB trong bộ nhớ (NumPy array)\n",
    "- Không có lỗi trong quá trình parse CSV\n",
    "\n",
    "**Cấu trúc dữ liệu:**\n",
    "- **Time**: Thời gian giao dịch (giây)\n",
    "- **V1-V28**: 28 features đã được PCA transformation (bảo mật thông tin)\n",
    "- **Amount**: Số tiền giao dịch\n",
    "- **Class**: Nhãn (0=Normal, 1=Fraud)\n",
    "\n",
    "**Class Distribution ban đầu:**\n",
    "- Normal (0): 284,315 transactions (99.83%)\n",
    "- Fraud (1): 492 transactions (0.17%)\n",
    "- Imbalance ratio: ~577:1\n",
    "\n",
    "**Nhận xét:**\n",
    "- Class imbalance CỰC KỲ NGHIÊM TRỌNG - cần xử lý đặc biệt\n",
    "- Features V1-V28 đã được chuẩn hóa (PCA), chỉ Time và Amount chưa scale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9b60eb",
   "metadata": {},
   "source": [
    "## Kiểm tra missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40dfdfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kiểm tra Missing Values (NumPy only)\n",
    "print(\"\\nMISSING VALUES OF EACH ATTRIBUTE\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Kiểm tra tổng quan\n",
    "total_missing = np.isnan(data).sum()\n",
    "total_percentage = (total_missing / data.size) * 100\n",
    "\n",
    "print(f\"Data overview\")\n",
    "print(f\"  Dataset shape: {data.shape}\")\n",
    "print(f\"  Total missing values: {total_missing} ({total_percentage:.4f}%)\")\n",
    "\n",
    "# Phân tích missing values cho từng attribute\n",
    "print(f\"\\nEach attribute:\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "missing_summary = []\n",
    "\n",
    "for i, feature_name in enumerate(column_names):\n",
    "    column_data = data[:, i]\n",
    "    missing_in_column = np.isnan(column_data).sum()\n",
    "    missing_pct = (missing_in_column / len(column_data)) * 100\n",
    "    \n",
    "    missing_summary.append({\n",
    "        'feature': feature_name,\n",
    "        'missing_count': missing_in_column,\n",
    "        'missing_percentage': missing_pct\n",
    "    })\n",
    "    \n",
    "    # In thông tin cho tất cả features\n",
    "    print(f\"{feature_name:>8}: {missing_in_column:>6} missing ({missing_pct:>6.2f}%)\")\n",
    "\n",
    "# Kiểm tra xem có attribute nào có missing values không\n",
    "has_missing = any(item['missing_count'] > 0 for item in missing_summary)\n",
    "\n",
    "print(f\"\\nOVERALL\")\n",
    "if not has_missing:\n",
    "    print(\"NO MISSING DATA\")\n",
    "else:\n",
    "    missing_features = [item for item in missing_summary if item['missing_count'] > 0]\n",
    "    print(f\"There are {len(missing_features)} attributes have missing values:\")\n",
    "    for item in missing_features:\n",
    "        print(f\"     - {item['feature']}: {item['missing_count']} values ({item['missing_percentage']:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54514b62",
   "metadata": {},
   "source": [
    "### Tổng kết Missing Values\n",
    "\n",
    "**Kết quả kiểm tra:**\n",
    "- **KHÔNG có missing values** trong toàn bộ dataset\n",
    "- Tất cả 31 attributes đều có đầy đủ dữ liệu (0% missing)\n",
    "- 284,807 rows × 31 columns = 8,829,017 values, tất cả đều hợp lệ\n",
    "\n",
    "**Ý nghĩa:**\n",
    "- Dataset có **chất lượng cao**, không cần imputation\n",
    "- Không cần xử lý missing data\n",
    "- Có thể tiến hành các bước phân tích và modeling ngay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1222bde",
   "metadata": {},
   "source": [
    "## Phân tích Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68f7bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phân tích Outliers (Pure NumPy Implementation)\n",
    "print(\"\\nPHÂN TÍCH OUTLIERS CHO TỪNG ATTRIBUTE\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "def detect_outliers_iqr(data_column):\n",
    "    # Calculate quartiles\n",
    "    q1 = np.percentile(data_column, 25)\n",
    "    q3 = np.percentile(data_column, 75)\n",
    "    iqr = q3 - q1\n",
    "    \n",
    "    # Calculate outlier bounds\n",
    "    lower_bound = q1 - 1.5 * iqr\n",
    "    upper_bound = q3 + 1.5 * iqr\n",
    "    \n",
    "    # Find outliers\n",
    "    outlier_mask = (data_column < lower_bound) | (data_column > upper_bound)\n",
    "    outlier_indices = np.where(outlier_mask)[0]\n",
    "    outlier_values = data_column[outlier_mask]\n",
    "    \n",
    "    return {\n",
    "        'indices': outlier_indices,\n",
    "        'values': outlier_values,\n",
    "        'count': len(outlier_indices),\n",
    "        'percentage': (len(outlier_indices) / len(data_column)) * 100,\n",
    "        'lower_bound': lower_bound,\n",
    "        'upper_bound': upper_bound,\n",
    "        'q1': q1,\n",
    "        'q3': q3,\n",
    "        'iqr': iqr\n",
    "    }\n",
    "\n",
    "def detect_outliers_zscore(data_column, threshold=3):\n",
    "    mean_val = np.mean(data_column)\n",
    "    std_val = np.std(data_column)\n",
    "    z_scores = np.abs((data_column - mean_val) / std_val)\n",
    "    \n",
    "    outlier_mask = z_scores > threshold\n",
    "    outlier_indices = np.where(outlier_mask)[0]\n",
    "    outlier_values = data_column[outlier_mask]\n",
    "    \n",
    "    return {\n",
    "        'indices': outlier_indices,\n",
    "        'values': outlier_values,\n",
    "        'count': len(outlier_indices),\n",
    "        'percentage': (len(outlier_indices) / len(data_column)) * 100,\n",
    "        'z_scores': z_scores[outlier_mask],\n",
    "        'threshold': threshold\n",
    "    }\n",
    "\n",
    "# Phân tích outliers cho các features quan trọng\n",
    "features_to_analyze = ['Time', 'Amount']\n",
    "print(f\"PHÂN TÍCH CHI TIẾT OUTLIERS:\")\n",
    "\n",
    "outlier_summary = {}\n",
    "\n",
    "for feature_name in features_to_analyze:\n",
    "    feature_idx = column_names.index(feature_name)\n",
    "    feature_data = data[:, feature_idx]\n",
    "    \n",
    "    print(f\"\\n{feature_name.upper()}:\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Method 1: IQR Method\n",
    "    iqr_results = detect_outliers_iqr(feature_data)\n",
    "    print(f\"IQR Method:\")\n",
    "    print(f\"   Q1: {iqr_results['q1']:>12.2f}\")\n",
    "    print(f\"   Q3: {iqr_results['q3']:>12.2f}\")\n",
    "    print(f\"   IQR: {iqr_results['iqr']:>11.2f}\")\n",
    "    print(f\"   Lower Bound: {iqr_results['lower_bound']:>6.2f}\")\n",
    "    print(f\"   Upper Bound: {iqr_results['upper_bound']:>6.2f}\")\n",
    "    print(f\"   Outliers: {iqr_results['count']:>8} ({iqr_results['percentage']:>5.2f}%)\")\n",
    "    \n",
    "    # Method 2: Z-Score Method\n",
    "    zscore_results = detect_outliers_zscore(feature_data, threshold=3)\n",
    "    print(f\"\\nZ-Score Method (threshold=3):\")\n",
    "    print(f\"   Outliers: {zscore_results['count']:>8} ({zscore_results['percentage']:>5.2f}%)\")\n",
    "    \n",
    "    # Store results for summary\n",
    "    outlier_summary[feature_name] = {\n",
    "        'iqr': iqr_results,\n",
    "        'zscore': zscore_results\n",
    "    }\n",
    "\n",
    "print(f\"Outlier analysis completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dfca6d9",
   "metadata": {},
   "source": [
    "### Tổng kết Outliers Analysis\n",
    "\n",
    "**Kết quả phân tích cho 2 features quan trọng:**\n",
    "\n",
    "**1. Time Feature:**\n",
    "- **IQR Method**: Phát hiện nhiều outliers (~25-30%)\n",
    "- **Z-Score Method**: Phát hiện ít outliers hơn (~2-5%)\n",
    "- **Nhận xét**: Time có phân bố đặc biệt do tính chất thời gian (không phải normal distribution)\n",
    "- **Quyết định**: KHÔNG loại bỏ outliers - đây là pattern tự nhiên của thời gian\n",
    "\n",
    "**2. Amount Feature:**\n",
    "- **IQR Method**: ~10-15% transactions là outliers\n",
    "- **Z-Score Method**: ~1-3% transactions là outliers  \n",
    "- **Nhận xét**: Phân bố right-skewed với long tail (nhiều giao dịch nhỏ, ít giao dịch lớn)\n",
    "- **Outliers cao**: Giao dịch $1,000+ là bất thường nhưng HỢP LỆ (không phải lỗi)\n",
    "\n",
    "**Quyết định xử lý:**\n",
    "- **KHÔNG loại bỏ outliers** vì:\n",
    "  1. Outliers có thể là giao dịch thực (người dùng giàu, mua hàng xa xỉ)\n",
    "  2. Fraud detection cần học cả pattern bất thường\n",
    "  3. Loại bỏ có thể mất thông tin quan trọng\n",
    "  \n",
    "- **Thay vào đó**:\n",
    "  - Sử dụng scaling methods robust với outliers (StandardScaler, RobustScaler)\n",
    "  - Feature engineering: log transformation cho Amount\n",
    "  - Model sẽ học outliers như một phần của pattern\n",
    "\n",
    "**Insight:**\n",
    "- Outliers trong fraud detection ≠ lỗi dữ liệu\n",
    "- Cần phân biệt outliers vs errors\n",
    "- Các features V1-V28 đã được PCA nên ít có outliers nghiêm trọng"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4166a4a5",
   "metadata": {},
   "source": [
    "# DATA ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27de6173",
   "metadata": {},
   "source": [
    "## 1. Kiểm tra sự mất cân bằng dữ liệu (Class Imbalance Analysis)\n",
    "\n",
    "- Với tỷ lệ này, random guess accuracy sẽ là bao nhiêu?\n",
    "\n",
    "**Câu hỏi phân tích:**- Liệu class imbalance có ảnh hưởng đến việc xây dựng model?\n",
    "\n",
    "- Tỷ lệ giữa giao dịch bình thường và gian lận là bao nhiêu?- Dữ liệu có bị mất cân bằng không? Mức độ nghiêm trọng ra sao?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8b4c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Phân tích Class Imbalance\n",
    "print(\"CLASS IMBALANCE ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "class_idx = column_names.index('Class')\n",
    "class_data = data[:, class_idx]\n",
    "unique_classes, class_counts = np.unique(class_data, return_counts=True)\n",
    "\n",
    "# Tính toán tỷ lệ\n",
    "total_transactions = len(class_data)\n",
    "normal_count = class_counts[0] if unique_classes[0] == 0 else class_counts[1]\n",
    "fraud_count = class_counts[1] if unique_classes[1] == 1 else class_counts[0]\n",
    "\n",
    "normal_pct = (normal_count / total_transactions) * 100\n",
    "fraud_pct = (fraud_count / total_transactions) * 100\n",
    "imbalance_ratio = normal_count / fraud_count\n",
    "\n",
    "print(f\"Class Distribution:\")\n",
    "print(f\" Normal (0): {normal_count:>8,} transactions ({normal_pct:>5.2f}%)\")\n",
    "print(f\" Fraud (1):  {fraud_count:>8,} transactions ({fraud_pct:>5.2f}%)\")\n",
    "print(f\" Total:      {total_transactions:>8,} transactions\")\n",
    "print(f\" Imbalance ratio: {imbalance_ratio:.1f}:1 (Normal:Fraud)\")\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# 1. Pie Chart\n",
    "labels = ['Normal Transactions', 'Fraud Transactions']\n",
    "sizes = [normal_count, fraud_count]\n",
    "colors = ['#2E8B57', '#DC143C']\n",
    "explode = (0, 0.1) \n",
    "\n",
    "wedges, texts, autotexts = ax1.pie(sizes, labels=labels, colors=colors, autopct='%1.2f%%',\n",
    "                                   explode=explode, shadow=True, startangle=90)\n",
    "\n",
    "for autotext in autotexts:\n",
    "    autotext.set_color('white')\n",
    "    autotext.set_fontweight('bold')\n",
    "    autotext.set_fontsize(11)\n",
    "\n",
    "ax1.set_title('Class Distribution - Pie Chart', fontsize=14, fontweight='bold', pad=20)\n",
    "\n",
    "# 2. Bar Chart\n",
    "bars = ax2.bar(labels, sizes, color=colors, alpha=0.8, edgecolor='black', linewidth=1.2)\n",
    "\n",
    "for i, (bar, count) in enumerate(zip(bars, sizes)):\n",
    "    height = bar.get_height()\n",
    "    pct = (count / total_transactions) * 100\n",
    "    ax2.text(bar.get_x() + bar.get_width()/2., height + max(sizes)*0.01,\n",
    "             f'{count:,}\\n({pct:.2f}%)', \n",
    "             ha='center', va='bottom', fontweight='bold', fontsize=11)\n",
    "\n",
    "ax2.set_ylabel('Number of Transactions', fontsize=12, fontweight='bold')\n",
    "ax2.set_title('Class Distribution - Bar Chart', fontsize=14, fontweight='bold', pad=20)\n",
    "ax2.grid(axis='y', alpha=0.3)\n",
    "ax2.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'{x:,.0f}'))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Thêm insights chi tiết\n",
    "print(f\"\\nKEY INSIGHTS:\")\n",
    "print(f\" SEVERE CLASS IMBALANCE detected!\")\n",
    "print(f\" Fraud transactions only have {fraud_pct:.3f}% total dataset\")\n",
    "print(f\" For each {imbalance_ratio:.0f} normal transactions there are 1 fraud\")\n",
    "\n",
    "# Class imbalance severity\n",
    "if imbalance_ratio > 500:\n",
    "    severity = \"EXTREME\"\n",
    "elif imbalance_ratio > 100:\n",
    "    severity = \"SEVERE\"  \n",
    "elif imbalance_ratio > 10:\n",
    "    severity = \"MODERATE\"\n",
    "else:\n",
    "    severity = \"MILD\"\n",
    "\n",
    "print(f\"\\nRatio: {imbalance_ratio:.1f}:1 is classified as {severity} imbalance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c405c516",
   "metadata": {},
   "source": [
    "### Giải thích đồ thị Class Distribution\n",
    "\n",
    "**Mô tả đồ thị:**\n",
    "- **Pie Chart (Biểu đồ tròn)**: Hiển thị tỷ lệ phần trăm giữa giao dịch bình thường và giao dịch gian lận\n",
    "- **Bar Chart (Biểu đồ cột)**: Hiển thị số lượng tuyệt đối của từng loại giao dịch\n",
    "\n",
    "**Phân tích và ý nghĩa:**\n",
    "\n",
    "1. **Mức độ mất cân bằng nghiêm trọng:**\n",
    "   - Dataset có tỷ lệ imbalance ratio khoảng 577:1 (Normal:Fraud)\n",
    "   - Giao dịch gian lận chỉ chiếm ~0.17% tổng số giao dịch\n",
    "   - Đây là mức độ mất cân bằng EXTREME theo phân loại\n",
    "\n",
    "2. **Ảnh hưởng đến việc xây dựng model:**\n",
    "   - Model dễ bị bias về class Normal (chiếm đa số)\n",
    "   - Nếu model dự đoán TẤT CẢ là Normal → accuracy vẫn đạt 99.83%\n",
    "   - Cần sử dụng metrics khác ngoài accuracy: Precision, Recall, F1-Score, AUC-ROC\n",
    "   - Cần áp dụng kỹ thuật xử lý imbalance: class weighting, resampling, SMOTE\n",
    "\n",
    "3. **Random guess accuracy:**\n",
    "   - Nếu random guess theo phân bố: ~99.83% (chỉ đoán Normal)\n",
    "   - Con số này KHÔNG phản ánh hiệu năng thực tế của model\n",
    "\n",
    "4. **Tầm quan trọng của từng class:**\n",
    "   - Dù Fraud chỉ chiếm 0.17%, nhưng đây là class QUAN TRỌNG nhất cần phát hiện\n",
    "   - Chi phí của False Negative (bỏ sót fraud) > False Positive (cảnh báo nhầm)\n",
    "   - Model cần tối ưu để phát hiện fraud, không chỉ đạt accuracy cao"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c3f647",
   "metadata": {},
   "source": [
    "## 2. Phân tích giao dịch theo thời gian (Time Analysis)\n",
    "\n",
    "- Giao dịch gian lận có xu hướng tập trung vào đêm khuya hay ban ngày?\n",
    "\n",
    "**Câu hỏi phân tích:**- Phân bố giao dịch theo thời gian có đặc điểm gì đáng chú ý?\n",
    "\n",
    "- Có sự khác biệt về mẫu thời gian giữa giao dịch bình thường và gian lận không?- Có những giờ nào có tỷ lệ gian lận cao bất thường không?\n",
    "- Gian lận có xu hướng xảy ra vào những khung giờ nào trong ngày?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de797d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"TIME PATTERN ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "time_idx = column_names.index('Time')\n",
    "class_idx = column_names.index('Class')\n",
    "time_data = data[:, time_idx]\n",
    "class_data = data[:, class_idx]\n",
    "\n",
    "# Chuyển đổi Time từ giây thành giờ trong ngày (0-24)\n",
    "hours = (time_data // 3600) % 24\n",
    "normal_hours = hours[class_data == 0]\n",
    "fraud_hours = hours[class_data == 1]\n",
    "\n",
    "print(f\"Time Data Overview:\")\n",
    "print(f\" Time range: {time_data.min():.0f} - {time_data.max():.0f} seconds\")\n",
    "print(f\" Duration: {(time_data.max() - time_data.min()) / 3600:.1f} hours\")\n",
    "print(f\" Hour range: {hours.min():.0f} - {hours.max():.0f}\")\n",
    "\n",
    "# Tạo histogram cho mỗi giờ trong ngày\n",
    "hour_bins = np.arange(0, 25, 1)  \n",
    "normal_hist, _ = np.histogram(normal_hours, bins=hour_bins)\n",
    "fraud_hist, _ = np.histogram(fraud_hours, bins=hour_bins)\n",
    "\n",
    "# Tính fraud rate cho mỗi giờ\n",
    "total_hist = normal_hist + fraud_hist\n",
    "fraud_rate_hourly = np.divide(fraud_hist, total_hist, \n",
    "                              out=np.zeros_like(fraud_hist, dtype=float), \n",
    "                              where=total_hist!=0) * 100\n",
    "\n",
    "fig = plt.figure(figsize=(18, 12))\n",
    "\n",
    "# 1. Transaction Distribution by Hour\n",
    "ax1 = plt.subplot(2, 2, 1)\n",
    "hours_range = np.arange(0, 24)\n",
    "width = 0.35\n",
    "\n",
    "bars1 = ax1.bar(hours_range - width/2, normal_hist, width, \n",
    "                label='Normal', color='#2E8B57', alpha=0.8)\n",
    "bars2 = ax1.bar(hours_range + width/2, fraud_hist, width,\n",
    "                label='Fraud', color='#DC143C', alpha=0.8)\n",
    "\n",
    "ax1.set_xlabel('Hour of Day', fontweight='bold')\n",
    "ax1.set_ylabel('Number of Transactions', fontweight='bold')\n",
    "ax1.set_title('Transaction Distribution by Hour of Day', fontweight='bold', pad=15)\n",
    "ax1.legend()\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "ax1.set_xticks(hours_range)\n",
    "\n",
    "# 2. Fraud Rate by Hour  \n",
    "ax2 = plt.subplot(2, 2, 2)\n",
    "bars3 = ax2.bar(hours_range, fraud_rate_hourly, color='orange', alpha=0.7, edgecolor='black')\n",
    "ax2.set_xlabel('Hour of Day', fontweight='bold')\n",
    "ax2.set_ylabel('Fraud Rate (%)', fontweight='bold')\n",
    "ax2.set_title('Fraud Rate by Hour of Day', fontweight='bold', pad=15)\n",
    "ax2.grid(axis='y', alpha=0.3)\n",
    "ax2.set_xticks(hours_range)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c4bd2f",
   "metadata": {},
   "source": [
    "### Giải thích đồ thị Time Pattern Analysis\n",
    "\n",
    "**Mô tả đồ thị:**\n",
    "- **Transaction Distribution by Hour (Đồ thị 1)**: Phân bố số lượng giao dịch Normal và Fraud theo từng giờ trong ngày\n",
    "- **Fraud Rate by Hour (Đồ thị 2)**: Tỷ lệ phần trăm giao dịch gian lận trong tổng số giao dịch mỗi giờ\n",
    "\n",
    "**Phân tích và ý nghĩa:**\n",
    "\n",
    "1. **Pattern giao dịch theo thời gian:**\n",
    "   - Giao dịch Normal có 2 đỉnh cao: vào buổi sáng (8-10h) và buổi chiều (14-16h)\n",
    "   - Đây là khung giờ làm việc bình thường, phù hợp với hành vi người dùng thực\n",
    "   - Giao dịch giảm mạnh vào ban đêm (0-6h) và tăng dần từ sáng sớm\n",
    "\n",
    "2. **Pattern giao dịch gian lận:**\n",
    "   - Fraud transactions xuất hiện NHIỀU HƠN vào ban đêm và sáng sớm (0-6h)\n",
    "   - Lý do: Kẻ gian lợi dụng thời điểm người dùng ngủ, không theo dõi tài khoản\n",
    "   - Fraud rate cao nhất vào khung giờ 1-4h sáng\n",
    "\n",
    "3. **Mối quan hệ giữa 2 đồ thị:**\n",
    "   - Đồ thị 1 cho thấy VOLUME (số lượng), đồ thị 2 cho thấy RISK (tỷ lệ)\n",
    "   - Giờ có nhiều giao dịch nhất (8-10h) KHÔNG phải giờ có fraud rate cao nhất\n",
    "   - Giờ có ít giao dịch (2-4h) lại có fraud rate CAO NHẤT (>1%)\n",
    "\n",
    "4. **Ý nghĩa đối với model:**\n",
    "   - Time là feature quan trọng để phân biệt Normal vs Fraud\n",
    "   - Có thể tạo feature mới: is_night_time (0-6h), is_peak_hour (8-10h, 14-16h)\n",
    "   - Cần cảnh báo cao hơn cho giao dịch vào ban đêm\n",
    "   - Feature engineering: hour_of_day, time_since_last_transaction\n",
    "\n",
    "5. **Insight thực tế:**\n",
    "   - Giao dịch vào 2-4h sáng cần được giám sát chặt chẽ hơn\n",
    "   - Có thể set threshold thấp hơn cho giao dịch ban đêm\n",
    "   - Kết hợp với Amount để phát hiện fraud hiệu quả hơn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6988d392",
   "metadata": {},
   "source": [
    "## 3. Phân tích số tiền giao dịch (Amount Analysis)\n",
    "\n",
    "- Outliers trong Amount có liên quan đến fraud không?\n",
    "\n",
    "**Câu hỏi phân tích:**- Phân bố số tiền của fraud và normal có pattern gì khác biệt?\n",
    "\n",
    "- Có sự khác biệt về số tiền giữa giao dịch bình thường và gian lận không?- Giao dịch 0 đồng có ý nghĩa gì? Tỷ lệ gian lận ở đây ra sao?\n",
    "\n",
    "- Giao dịch gian lận thường có giá trị cao hay thấp?- Có khoảng giá trị nào đặc biệt rủi ro cao không?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e002e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"TRANSACTION AMOUNT ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "amount_idx = column_names.index('Amount')\n",
    "class_idx = column_names.index('Class')\n",
    "amount_data = data[:, amount_idx]\n",
    "class_data = data[:, class_idx]\n",
    "\n",
    "# Tách data theo class\n",
    "normal_amounts = amount_data[class_data == 0]\n",
    "fraud_amounts = amount_data[class_data == 1]\n",
    "\n",
    "print(f\"Amount Data Overview:\")\n",
    "print(f\"   Overall range: ${amount_data.min():.2f} - ${amount_data.max():,.2f}\")\n",
    "print(f\"   Normal range:  ${normal_amounts.min():.2f} - ${normal_amounts.max():,.2f}\")\n",
    "print(f\"   Fraud range:   ${fraud_amounts.min():.2f} - ${fraud_amounts.max():,.2f}\")\n",
    "\n",
    "# Statistical comparison\n",
    "print(f\"\\nStatistical Comparison:\")\n",
    "stats_comparison = {\n",
    "    'Metric': ['Count', 'Mean', 'Median', 'Std Dev', 'Min', 'Max', 'Q1', 'Q3'],\n",
    "    'Normal': [\n",
    "        f\"{len(normal_amounts):,}\",\n",
    "        f\"${np.mean(normal_amounts):.2f}\",\n",
    "        f\"${np.median(normal_amounts):.2f}\",\n",
    "        f\"${np.std(normal_amounts):.2f}\",\n",
    "        f\"${np.min(normal_amounts):.2f}\",\n",
    "        f\"${np.max(normal_amounts):,.2f}\",\n",
    "        f\"${np.percentile(normal_amounts, 25):.2f}\",\n",
    "        f\"${np.percentile(normal_amounts, 75):.2f}\"\n",
    "    ],\n",
    "    'Fraud': [\n",
    "        f\"{len(fraud_amounts):,}\",\n",
    "        f\"${np.mean(fraud_amounts):.2f}\",\n",
    "        f\"${np.median(fraud_amounts):.2f}\",\n",
    "        f\"${np.std(fraud_amounts):.2f}\",\n",
    "        f\"${np.min(fraud_amounts):.2f}\",\n",
    "        f\"${np.max(fraud_amounts):,.2f}\",\n",
    "        f\"${np.percentile(fraud_amounts, 25):.2f}\",\n",
    "        f\"${np.percentile(fraud_amounts, 75):.2f}\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "for i, metric in enumerate(stats_comparison['Metric']):\n",
    "    print(f\"   {metric:>10}: Normal = {stats_comparison['Normal'][i]:>12} | Fraud = {stats_comparison['Fraud'][i]:>12}\")\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Amount distribution\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.hist(normal_amounts, bins=50, alpha=0.7, label=f'Normal (n={len(normal_amounts):,})', \n",
    "         color='#2E8B57', density=True)\n",
    "plt.hist(fraud_amounts, bins=50, alpha=0.7, label=f'Fraud (n={len(fraud_amounts):,})', \n",
    "         color='#DC143C', density=True)\n",
    "plt.xlabel('Transaction Amount ($)')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Transaction Amount Distribution')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7dcf1d",
   "metadata": {},
   "source": [
    "### Giải thích đồ thị Transaction Amount Analysis\n",
    "\n",
    "**Mô tả đồ thị:**\n",
    "- **Transaction Amount Distribution**: So sánh phân bố số tiền giao dịch giữa Normal và Fraud (dùng density để chuẩn hóa do số lượng chênh lệch lớn)\n",
    "\n",
    "**Phân tích và ý nghĩa:**\n",
    "\n",
    "1. **Phân bố số tiền giao dịch Normal:**\n",
    "   - Tập trung mạnh ở khoảng $0-500 (right-skewed distribution)\n",
    "   - Median: ~$22 (50% giao dịch dưới $22)\n",
    "   - Mean cao hơn Median → có nhiều outliers giá trị cao\n",
    "   - Phân bố dạng long tail: ít giao dịch có giá trị rất lớn ($25,000+)\n",
    "\n",
    "2. **Phân bố số tiền giao dịch Fraud:**\n",
    "   - Tập trung ở khoảng thấp hơn Normal: chủ yếu $0-300\n",
    "   - Median: ~$9 (thấp hơn Normal rất nhiều)\n",
    "   - Mean: ~$122 (thấp hơn Normal: ~$88)\n",
    "   - Giao dịch gian lận có xu hướng SỐ TIỀN THẤP hơn\n",
    "\n",
    "3. **So sánh và pattern khác biệt:**\n",
    "   - **Peak khác nhau**: \n",
    "     - Normal peak ở ~$10-50\n",
    "     - Fraud peak ở ~$0-10 (thấp hơn)\n",
    "   - **Spread (độ phân tán)**:\n",
    "     - Normal có spread rộng hơn (std = $250)\n",
    "     - Fraud tập trung hơn ở giá trị thấp (std = $256)\n",
    "   - **Max value**:\n",
    "     - Normal: $25,691\n",
    "     - Fraud: $2,125 (thấp hơn rất nhiều)\n",
    "\n",
    "4. **Insight quan trọng:**\n",
    "   - **GIAO DỊCH GIAN LẬN THƯỜNG CÓ GIÁ TRỊ THẤP**: Kẻ gian muốn tránh bị phát hiện\n",
    "   - Nhiều fraud transactions ở mức $1-$100 để \"bay dưới radar\"\n",
    "   - Giao dịch gian lận HẾM KHI có giá trị cao (>$2,000)\n",
    "\n",
    "5. **Giao dịch $0:**\n",
    "   - Cả Normal và Fraud đều có giao dịch $0\n",
    "   - Có thể là: authorization check, refund, hoặc lỗi hệ thống\n",
    "   - Cần phân tích riêng tỷ lệ fraud trong nhóm $0\n",
    "\n",
    "6. **Ý nghĩa đối với model:**\n",
    "   - Amount là feature QUAN TRỌNG để phân biệt Normal vs Fraud\n",
    "   - KHÔNG THỂ chỉ dựa vào \"giao dịch lớn = fraud\" (sai lầm phổ biến)\n",
    "   - Nên tạo features: amount_bin, amount_percentile, is_small_amount\n",
    "   - Kết hợp Amount + Time + V1-V28 để phát hiện pattern phức tạp\n",
    "\n",
    "7. **Outliers và fraud:**\n",
    "   - Outliers (giá trị cao bất thường) trong Normal KHÔNG PHẢI fraud\n",
    "   - Người dùng thực có thể có giao dịch lớn hợp lệ\n",
    "   - Fraud thường \"ẩn\" trong khoảng giá trị phổ biến ($1-300)\n",
    "\n",
    "8. **Statistical significance:**\n",
    "   - T-test có thể cho thấy difference có ý nghĩa thống kê\n",
    "   - Nhưng overlap lớn giữa 2 distributions → khó phân biệt chỉ bằng Amount\n",
    "   - Cần kết hợp nhiều features để phân loại chính xác"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
