{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b24db216",
   "metadata": {},
   "source": [
    "# Credit Card Fraud Detection - Data Exploration\n",
    "\n",
    "## HỌ VÀ TÊN: Cao Tấn Hoàng Huy\n",
    "## MSSV: 23127051"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d458b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Khai báo các thư viện cần thiết\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Setup\n",
    "np.random.seed(42)\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0701ba",
   "metadata": {},
   "source": [
    "# Data exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5292ae6c",
   "metadata": {},
   "source": [
    "## Load dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05b1f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('creditcard.csv', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "# Skip header và lấy tên columns\n",
    "header = lines[0].strip().replace('\"', '').split(',')\n",
    "print(f\"Found {len(header)} columns: {header}\")\n",
    "\n",
    "data_list = []\n",
    "error_lines = []\n",
    "\n",
    "for i, line in enumerate(lines[1:], 1):\n",
    "    try:\n",
    "        # Xử lý dòng và chuyển đổi sang float\n",
    "        line = line.strip()\n",
    "        if not line:  # Skip empty lines\n",
    "            continue\n",
    "            \n",
    "        values = line.split(',')\n",
    "        \n",
    "        # Remove quotes if present và convert to float\n",
    "        float_values = []\n",
    "        for val in values:\n",
    "            val = val.strip().strip('\"')\n",
    "            float_values.append(float(val))\n",
    "        \n",
    "        if len(float_values) == 31:  # Ensure we have all columns\n",
    "            data_list.append(float_values)\n",
    "        else:\n",
    "            error_lines.append((i, len(float_values)))\n",
    "            \n",
    "    except Exception as e:\n",
    "        error_lines.append((i, str(e)))\n",
    "        if len(error_lines) < 10:  # Only show first 10 errors\n",
    "            print(f\"Error at line {i}: {e}\")\n",
    "            print(f\"Line content: {line[:100]}\")\n",
    "\n",
    "if error_lines:\n",
    "    print(f\"Found {len(error_lines)} problematic lines\")\n",
    "else:\n",
    "    print(\"All lines parsed successfully\")\n",
    "\n",
    "data = np.array(data_list, dtype=np.float64)\n",
    "\n",
    "print(f\"\\nDATASET OVERVIEW:\")\n",
    "print(f\"Dataset loaded successfully!\")\n",
    "print(f\"Shape: {data.shape}\")\n",
    "print(f\"Type: {data.dtype}\")\n",
    "print(f\"Size: {data.nbytes / (1024*1024):.2f} MB\")\n",
    "\n",
    "# Tạo mapping cho columns\n",
    "column_names = header\n",
    "print(f\"\\nCOLUMN INFORMATION:\")\n",
    "for i, col_name in enumerate(column_names):\n",
    "    print(f\"Column {i:2d}: {col_name}\")\n",
    "\n",
    "# Quick preview của data\n",
    "print(f\"\\nDATA PREVIEW:\")\n",
    "print(f\"First 5 rows (showing Time, V1, V2, Amount, Class):\")\n",
    "preview_cols = [0, 1, 2, 29, 30]  # Time, V1, V2, Amount, Class\n",
    "preview_names = [column_names[i] for i in preview_cols]\n",
    "\n",
    "for i in range(min(5, data.shape[0])):\n",
    "    values = [f\"{data[i, col]:.2f}\" for col in preview_cols]\n",
    "    print(f\"   Row {i+1}: \" + \" | \".join(f\"{name}={val}\" for name, val in zip(preview_names, values)))\n",
    "\n",
    "# Basic statistics\n",
    "print(f\"\\nBASIC STATISTICS:\")\n",
    "print(f\"Total transactions: {data.shape[0]:,}\")\n",
    "print(f\"Total features: {data.shape[1]}\")\n",
    "\n",
    "# Class distribution\n",
    "class_column = data[:, -1]  # Last column is Class\n",
    "unique_classes, class_counts = np.unique(class_column, return_counts=True)\n",
    "print(f\"\\nCLASS DISTRIBUTION:\")\n",
    "for cls, count in zip(unique_classes, class_counts):\n",
    "    percentage = (count / len(class_column)) * 100\n",
    "    label = \"Normal\" if cls == 0.0 else \"Fraud\"\n",
    "    print(f\" {label} ({cls}): {count:>6,} transactions ({percentage:>5.2f}%)\")\n",
    "\n",
    "# Calculate imbalance ratio\n",
    "if len(unique_classes) == 2:\n",
    "    normal_count = class_counts[0] if unique_classes[0] == 0 else class_counts[1]\n",
    "    fraud_count = class_counts[1] if unique_classes[1] == 1 else class_counts[0]\n",
    "    imbalance_ratio = normal_count / fraud_count\n",
    "    print(f\"Imbalance ratio: {imbalance_ratio:.1f}:1 (Normal:Fraud)\")\n",
    "\n",
    "print(f\"\\nDataset ready for exploration!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9b60eb",
   "metadata": {},
   "source": [
    "## Kiểm tra missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40dfdfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kiểm tra Missing Values (NumPy only)\n",
    "print(\"\\nMISSING VALUES OF EACH ATTRIBUTE\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Kiểm tra tổng quan\n",
    "total_missing = np.isnan(data).sum()\n",
    "total_percentage = (total_missing / data.size) * 100\n",
    "\n",
    "print(f\"Data overview\")\n",
    "print(f\"  Dataset shape: {data.shape}\")\n",
    "print(f\"  Total missing values: {total_missing} ({total_percentage:.4f}%)\")\n",
    "\n",
    "# Phân tích missing values cho từng attribute\n",
    "print(f\"\\nEach attribute:\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "missing_summary = []\n",
    "\n",
    "for i, feature_name in enumerate(column_names):\n",
    "    column_data = data[:, i]\n",
    "    missing_in_column = np.isnan(column_data).sum()\n",
    "    missing_pct = (missing_in_column / len(column_data)) * 100\n",
    "    \n",
    "    missing_summary.append({\n",
    "        'feature': feature_name,\n",
    "        'missing_count': missing_in_column,\n",
    "        'missing_percentage': missing_pct\n",
    "    })\n",
    "    \n",
    "    # In thông tin cho tất cả features\n",
    "    print(f\"{feature_name:>8}: {missing_in_column:>6} missing ({missing_pct:>6.2f}%)\")\n",
    "\n",
    "# Kiểm tra xem có attribute nào có missing values không\n",
    "has_missing = any(item['missing_count'] > 0 for item in missing_summary)\n",
    "\n",
    "print(f\"\\nOVERALL\")\n",
    "if not has_missing:\n",
    "    print(\"NO MISSING DATA\")\n",
    "else:\n",
    "    missing_features = [item for item in missing_summary if item['missing_count'] > 0]\n",
    "    print(f\"There are {len(missing_features)} attributes have missing values:\")\n",
    "    for item in missing_features:\n",
    "        print(f\"     - {item['feature']}: {item['missing_count']} values ({item['missing_percentage']:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1222bde",
   "metadata": {},
   "source": [
    "## Phân tích Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68f7bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phân tích Outliers (Pure NumPy Implementation)\n",
    "print(\"\\nPHÂN TÍCH OUTLIERS CHO TỪNG ATTRIBUTE\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "def detect_outliers_iqr(data_column):\n",
    "    # Calculate quartiles\n",
    "    q1 = np.percentile(data_column, 25)\n",
    "    q3 = np.percentile(data_column, 75)\n",
    "    iqr = q3 - q1\n",
    "    \n",
    "    # Calculate outlier bounds\n",
    "    lower_bound = q1 - 1.5 * iqr\n",
    "    upper_bound = q3 + 1.5 * iqr\n",
    "    \n",
    "    # Find outliers\n",
    "    outlier_mask = (data_column < lower_bound) | (data_column > upper_bound)\n",
    "    outlier_indices = np.where(outlier_mask)[0]\n",
    "    outlier_values = data_column[outlier_mask]\n",
    "    \n",
    "    return {\n",
    "        'indices': outlier_indices,\n",
    "        'values': outlier_values,\n",
    "        'count': len(outlier_indices),\n",
    "        'percentage': (len(outlier_indices) / len(data_column)) * 100,\n",
    "        'lower_bound': lower_bound,\n",
    "        'upper_bound': upper_bound,\n",
    "        'q1': q1,\n",
    "        'q3': q3,\n",
    "        'iqr': iqr\n",
    "    }\n",
    "\n",
    "def detect_outliers_zscore(data_column, threshold=3):\n",
    "    mean_val = np.mean(data_column)\n",
    "    std_val = np.std(data_column)\n",
    "    z_scores = np.abs((data_column - mean_val) / std_val)\n",
    "    \n",
    "    outlier_mask = z_scores > threshold\n",
    "    outlier_indices = np.where(outlier_mask)[0]\n",
    "    outlier_values = data_column[outlier_mask]\n",
    "    \n",
    "    return {\n",
    "        'indices': outlier_indices,\n",
    "        'values': outlier_values,\n",
    "        'count': len(outlier_indices),\n",
    "        'percentage': (len(outlier_indices) / len(data_column)) * 100,\n",
    "        'z_scores': z_scores[outlier_mask],\n",
    "        'threshold': threshold\n",
    "    }\n",
    "\n",
    "# Phân tích outliers cho các features quan trọng\n",
    "features_to_analyze = ['Time', 'Amount']\n",
    "print(f\"PHÂN TÍCH CHI TIẾT OUTLIERS:\")\n",
    "\n",
    "outlier_summary = {}\n",
    "\n",
    "for feature_name in features_to_analyze:\n",
    "    feature_idx = column_names.index(feature_name)\n",
    "    feature_data = data[:, feature_idx]\n",
    "    \n",
    "    print(f\"\\n{feature_name.upper()}:\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Method 1: IQR Method\n",
    "    iqr_results = detect_outliers_iqr(feature_data)\n",
    "    print(f\"IQR Method:\")\n",
    "    print(f\"   Q1: {iqr_results['q1']:>12.2f}\")\n",
    "    print(f\"   Q3: {iqr_results['q3']:>12.2f}\")\n",
    "    print(f\"   IQR: {iqr_results['iqr']:>11.2f}\")\n",
    "    print(f\"   Lower Bound: {iqr_results['lower_bound']:>6.2f}\")\n",
    "    print(f\"   Upper Bound: {iqr_results['upper_bound']:>6.2f}\")\n",
    "    print(f\"   Outliers: {iqr_results['count']:>8} ({iqr_results['percentage']:>5.2f}%)\")\n",
    "    \n",
    "    # Method 2: Z-Score Method\n",
    "    zscore_results = detect_outliers_zscore(feature_data, threshold=3)\n",
    "    print(f\"\\nZ-Score Method (threshold=3):\")\n",
    "    print(f\"   Outliers: {zscore_results['count']:>8} ({zscore_results['percentage']:>5.2f}%)\")\n",
    "    \n",
    "    # Store results for summary\n",
    "    outlier_summary[feature_name] = {\n",
    "        'iqr': iqr_results,\n",
    "        'zscore': zscore_results\n",
    "    }\n",
    "\n",
    "print(f\"Outlier analysis completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4166a4a5",
   "metadata": {},
   "source": [
    "# DATA ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27de6173",
   "metadata": {},
   "source": [
    "## 1. Kiểm tra sự mất cân bằng dữ liệu (Class Imbalance Analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8b4c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Phân tích Class Imbalance\n",
    "print(\"CLASS IMBALANCE ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "class_idx = column_names.index('Class')\n",
    "class_data = data[:, class_idx]\n",
    "unique_classes, class_counts = np.unique(class_data, return_counts=True)\n",
    "\n",
    "# Tính toán tỷ lệ\n",
    "total_transactions = len(class_data)\n",
    "normal_count = class_counts[0] if unique_classes[0] == 0 else class_counts[1]\n",
    "fraud_count = class_counts[1] if unique_classes[1] == 1 else class_counts[0]\n",
    "\n",
    "normal_pct = (normal_count / total_transactions) * 100\n",
    "fraud_pct = (fraud_count / total_transactions) * 100\n",
    "imbalance_ratio = normal_count / fraud_count\n",
    "\n",
    "print(f\"Class Distribution:\")\n",
    "print(f\" Normal (0): {normal_count:>8,} transactions ({normal_pct:>5.2f}%)\")\n",
    "print(f\" Fraud (1):  {fraud_count:>8,} transactions ({fraud_pct:>5.2f}%)\")\n",
    "print(f\" Total:      {total_transactions:>8,} transactions\")\n",
    "print(f\" Imbalance ratio: {imbalance_ratio:.1f}:1 (Normal:Fraud)\")\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# 1. Pie Chart\n",
    "labels = ['Normal Transactions', 'Fraud Transactions']\n",
    "sizes = [normal_count, fraud_count]\n",
    "colors = ['#2E8B57', '#DC143C']\n",
    "explode = (0, 0.1) \n",
    "\n",
    "wedges, texts, autotexts = ax1.pie(sizes, labels=labels, colors=colors, autopct='%1.2f%%',\n",
    "                                   explode=explode, shadow=True, startangle=90)\n",
    "\n",
    "for autotext in autotexts:\n",
    "    autotext.set_color('white')\n",
    "    autotext.set_fontweight('bold')\n",
    "    autotext.set_fontsize(11)\n",
    "\n",
    "ax1.set_title('Class Distribution - Pie Chart', fontsize=14, fontweight='bold', pad=20)\n",
    "\n",
    "# 2. Bar Chart\n",
    "bars = ax2.bar(labels, sizes, color=colors, alpha=0.8, edgecolor='black', linewidth=1.2)\n",
    "\n",
    "for i, (bar, count) in enumerate(zip(bars, sizes)):\n",
    "    height = bar.get_height()\n",
    "    pct = (count / total_transactions) * 100\n",
    "    ax2.text(bar.get_x() + bar.get_width()/2., height + max(sizes)*0.01,\n",
    "             f'{count:,}\\n({pct:.2f}%)', \n",
    "             ha='center', va='bottom', fontweight='bold', fontsize=11)\n",
    "\n",
    "ax2.set_ylabel('Number of Transactions', fontsize=12, fontweight='bold')\n",
    "ax2.set_title('Class Distribution - Bar Chart', fontsize=14, fontweight='bold', pad=20)\n",
    "ax2.grid(axis='y', alpha=0.3)\n",
    "ax2.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'{x:,.0f}'))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Thêm insights chi tiết\n",
    "print(f\"\\nKEY INSIGHTS:\")\n",
    "print(f\" SEVERE CLASS IMBALANCE detected!\")\n",
    "print(f\" Fraud transactions only have {fraud_pct:.3f}% total dataset\")\n",
    "print(f\" For each {imbalance_ratio:.0f} normal transactions there are 1 fraud\")\n",
    "\n",
    "# Class imbalance severity\n",
    "if imbalance_ratio > 500:\n",
    "    severity = \"EXTREME\"\n",
    "elif imbalance_ratio > 100:\n",
    "    severity = \"SEVERE\"  \n",
    "elif imbalance_ratio > 10:\n",
    "    severity = \"MODERATE\"\n",
    "else:\n",
    "    severity = \"MILD\"\n",
    "\n",
    "print(f\"\\nRatio: {imbalance_ratio:.1f}:1 is classified as {severity} imbalance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c3f647",
   "metadata": {},
   "source": [
    "## 2. Phân tích giao dịch theo thời gian (Time Analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de797d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"TIME PATTERN ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "time_idx = column_names.index('Time')\n",
    "class_idx = column_names.index('Class')\n",
    "time_data = data[:, time_idx]\n",
    "class_data = data[:, class_idx]\n",
    "\n",
    "# Chuyển đổi Time từ giây thành giờ trong ngày (0-24)\n",
    "hours = (time_data // 3600) % 24\n",
    "normal_hours = hours[class_data == 0]\n",
    "fraud_hours = hours[class_data == 1]\n",
    "\n",
    "print(f\"Time Data Overview:\")\n",
    "print(f\" Time range: {time_data.min():.0f} - {time_data.max():.0f} seconds\")\n",
    "print(f\" Duration: {(time_data.max() - time_data.min()) / 3600:.1f} hours\")\n",
    "print(f\" Hour range: {hours.min():.0f} - {hours.max():.0f}\")\n",
    "\n",
    "# Tạo histogram cho mỗi giờ trong ngày\n",
    "hour_bins = np.arange(0, 25, 1)  \n",
    "normal_hist, _ = np.histogram(normal_hours, bins=hour_bins)\n",
    "fraud_hist, _ = np.histogram(fraud_hours, bins=hour_bins)\n",
    "\n",
    "# Tính fraud rate cho mỗi giờ\n",
    "total_hist = normal_hist + fraud_hist\n",
    "fraud_rate_hourly = np.divide(fraud_hist, total_hist, \n",
    "                              out=np.zeros_like(fraud_hist, dtype=float), \n",
    "                              where=total_hist!=0) * 100\n",
    "\n",
    "fig = plt.figure(figsize=(18, 12))\n",
    "\n",
    "# 1. Transaction Distribution by Hour\n",
    "ax1 = plt.subplot(2, 2, 1)\n",
    "hours_range = np.arange(0, 24)\n",
    "width = 0.35\n",
    "\n",
    "bars1 = ax1.bar(hours_range - width/2, normal_hist, width, \n",
    "                label='Normal', color='#2E8B57', alpha=0.8)\n",
    "bars2 = ax1.bar(hours_range + width/2, fraud_hist, width,\n",
    "                label='Fraud', color='#DC143C', alpha=0.8)\n",
    "\n",
    "ax1.set_xlabel('Hour of Day', fontweight='bold')\n",
    "ax1.set_ylabel('Number of Transactions', fontweight='bold')\n",
    "ax1.set_title('Transaction Distribution by Hour of Day', fontweight='bold', pad=15)\n",
    "ax1.legend()\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "ax1.set_xticks(hours_range)\n",
    "\n",
    "# 2. Fraud Rate by Hour  \n",
    "ax2 = plt.subplot(2, 2, 2)\n",
    "bars3 = ax2.bar(hours_range, fraud_rate_hourly, color='orange', alpha=0.7, edgecolor='black')\n",
    "ax2.set_xlabel('Hour of Day', fontweight='bold')\n",
    "ax2.set_ylabel('Fraud Rate (%)', fontweight='bold')\n",
    "ax2.set_title('Fraud Rate by Hour of Day', fontweight='bold', pad=15)\n",
    "ax2.grid(axis='y', alpha=0.3)\n",
    "ax2.set_xticks(hours_range)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6988d392",
   "metadata": {},
   "source": [
    "## 3. Phân tích số tiền giao dịch (Amount Analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e002e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"TRANSACTION AMOUNT ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "amount_idx = column_names.index('Amount')\n",
    "class_idx = column_names.index('Class')\n",
    "amount_data = data[:, amount_idx]\n",
    "class_data = data[:, class_idx]\n",
    "\n",
    "# Tách data theo class\n",
    "normal_amounts = amount_data[class_data == 0]\n",
    "fraud_amounts = amount_data[class_data == 1]\n",
    "\n",
    "print(f\"Amount Data Overview:\")\n",
    "print(f\"   Overall range: ${amount_data.min():.2f} - ${amount_data.max():,.2f}\")\n",
    "print(f\"   Normal range:  ${normal_amounts.min():.2f} - ${normal_amounts.max():,.2f}\")\n",
    "print(f\"   Fraud range:   ${fraud_amounts.min():.2f} - ${fraud_amounts.max():,.2f}\")\n",
    "\n",
    "# Statistical comparison\n",
    "print(f\"\\nStatistical Comparison:\")\n",
    "stats_comparison = {\n",
    "    'Metric': ['Count', 'Mean', 'Median', 'Std Dev', 'Min', 'Max', 'Q1', 'Q3'],\n",
    "    'Normal': [\n",
    "        f\"{len(normal_amounts):,}\",\n",
    "        f\"${np.mean(normal_amounts):.2f}\",\n",
    "        f\"${np.median(normal_amounts):.2f}\",\n",
    "        f\"${np.std(normal_amounts):.2f}\",\n",
    "        f\"${np.min(normal_amounts):.2f}\",\n",
    "        f\"${np.max(normal_amounts):,.2f}\",\n",
    "        f\"${np.percentile(normal_amounts, 25):.2f}\",\n",
    "        f\"${np.percentile(normal_amounts, 75):.2f}\"\n",
    "    ],\n",
    "    'Fraud': [\n",
    "        f\"{len(fraud_amounts):,}\",\n",
    "        f\"${np.mean(fraud_amounts):.2f}\",\n",
    "        f\"${np.median(fraud_amounts):.2f}\",\n",
    "        f\"${np.std(fraud_amounts):.2f}\",\n",
    "        f\"${np.min(fraud_amounts):.2f}\",\n",
    "        f\"${np.max(fraud_amounts):,.2f}\",\n",
    "        f\"${np.percentile(fraud_amounts, 25):.2f}\",\n",
    "        f\"${np.percentile(fraud_amounts, 75):.2f}\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "for i, metric in enumerate(stats_comparison['Metric']):\n",
    "    print(f\"   {metric:>10}: Normal = {stats_comparison['Normal'][i]:>12} | Fraud = {stats_comparison['Fraud'][i]:>12}\")\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Amount distribution\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.hist(normal_amounts, bins=50, alpha=0.7, label=f'Normal (n={len(normal_amounts):,})', \n",
    "         color='#2E8B57', density=True)\n",
    "plt.hist(fraud_amounts, bins=50, alpha=0.7, label=f'Fraud (n={len(fraud_amounts):,})', \n",
    "         color='#DC143C', density=True)\n",
    "plt.xlabel('Transaction Amount ($)')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Transaction Amount Distribution')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6bd9f7",
   "metadata": {},
   "source": [
    "## Save data for next notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943ec617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data for next notebook\n",
    "print(f\"\\nSaving processed data for next notebook...\")\n",
    "np.save('data_exploration_data.npy', data)\n",
    "np.save('data_exploration_column_names.npy', column_names)\n",
    "\n",
    "print(f\"\\nData exploration completed!\")\n",
    "print(f\"Files saved:\")\n",
    "print(f\"  - data_exploration_data.npy\")  \n",
    "print(f\"  - data_exploration_column_names.npy\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
